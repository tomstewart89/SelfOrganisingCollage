{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a37cc1ed8536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import PIL\n",
    "\n",
    "from photo_library import PhotoLibrary\n",
    "from SOM import SelfOrganisingMap\n",
    "from feature_extraction import FeatureExtractor\n",
    "from draw_samples import sample_from_unit_cube\n",
    "from patch_worker import Patchworker\n",
    "from utils import ravel_index, simplify_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--directory DIRECTORY] [--width WIDTH]\n",
      "                             [--height HEIGHT] [--feature FEATURE]\n",
      "                             [--epochs EPOCHS] [--reuse_penalty REUSE_PENALTY]\n",
      "                             [--sample_size SAMPLE_SIZE] [--border BORDER]\n",
      "                             [--magnify MAGNIFY]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-fd948f6d-123c-44ef-a5ed-364aac7c0593.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Make a lovely colourful collage from your photo library')\n",
    "parser.add_argument('--directory', default='/home/tom/Pictures/test_pics', type=str)\n",
    "parser.add_argument('--width', default=50, type=int)\n",
    "parser.add_argument('--height', default=35, type=int)\n",
    "parser.add_argument('--feature', default='mean_color', type=str)\n",
    "parser.add_argument('--epochs', default=20, type=int)\n",
    "parser.add_argument('--reuse_penalty', default=100., type=float)\n",
    "parser.add_argument('--sample_size', default=10, type=int)\n",
    "parser.add_argument('--border', default=20, type=int)\n",
    "parser.add_argument('--magnify', default=200, type=int)\n",
    "args = parser.parse_args()\n",
    "\n",
    "library = PhotoLibrary(args.directory)\n",
    "extractor = FeatureExtractor.factory(args.feature)\n",
    "som = SelfOrganisingMap(shape=[args.height, args.width, extractor.feature_dim], sigma=5., eta=1.)\n",
    "patch = Patchworker([args.height, args.width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cb6c7548c129>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mfeature_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(os.path.join(args.directory, args.feature), \"rb\") as f:\n",
    "        feature_dict = pickle.load(f)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    feature_dict = extractor.process_library(library)\n",
    "    with open(os.path.join(args.directory, args.feature), \"wb\") as f:\n",
    "        pickle.dump(feature_dict, f)\n",
    "\n",
    "# draw a subset of just the most interesting the entire photo library\n",
    "sample, keys = sample_from_unit_cube(feature_dict, args.sample_size)\n",
    "\n",
    "for _ in range(args.epochs):\n",
    "    for feature in sample[torch.randperm(args.sample_size),:]:\n",
    "        som.update(feature.cuda())\n",
    "        \n",
    "plt.imshow(som.grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now find the best vibing photo and stick it at its BMU\n",
    "times_used = torch.zeros(len(sample)).unsqueeze(1).cuda()\n",
    "layout = []\n",
    "\n",
    "# I can omit the occupied parts of the grid to speed this up\n",
    "while not patch.full():\n",
    "    dist = (sample.cuda().unsqueeze(1) - som.grid.reshape(-1,3).unsqueeze(0)).norm(dim=2)\n",
    "    dist += (times_used * args.reuse_penalty) # penalise the samples that have already been placed on the grid\n",
    "    dist[:, patch.occupied.reshape(-1)] = dist.max() # omit any neurons that already have a photo covering them\n",
    "\n",
    "    # find the neuron and sample that match most closely\n",
    "    winning_sample, winning_neuron = ravel_index(dist.argmin(), (som.grid.shape[0] * som.grid.shape[1]))\n",
    "    target_coord = torch.Tensor(ravel_index(winning_neuron, som.grid.shape[1]))\n",
    "    target_shape = simplify_shape(library[keys[winning_sample]].size)\n",
    "\n",
    "    # add the photo to the patch work\n",
    "    coord, shape = patch.add_patch(target_coord, target_shape)\n",
    "\n",
    "    layout.append([keys[winning_sample], coord, shape])\n",
    "\n",
    "    times_used[winning_sample] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = PIL.Image.new(\"RGB\", tuple(np.array(som.grid.shape[:2]) * args.magnify + args.border), \"white\")\n",
    "\n",
    "for key, coord, shape in layout:\n",
    "    img = library[key]\n",
    "\n",
    "    size_tup = (shape * args.magnify - args.border).numpy()\n",
    "    coord_tup = (coord * args.magnify + args.border - shape / 2).numpy()\n",
    "\n",
    "    crop = transforms.Compose([transforms.Resize(int(size_tup.min())), transforms.CenterCrop((size_tup[1],size_tup[0]))])\n",
    "\n",
    "    canvas.paste(crop(img), coord_tup)\n",
    "\n",
    "plt.imshow(canvas)\n",
    "plt.show()\n",
    "\n",
    "canvas.save('invite.png')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
